{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d15c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "import xgboost as xgb\n",
    "import math \n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from geopy.distance import great_circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da49ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_virgule(x):\n",
    "    try:return x.split('.')[0]\n",
    "    except:return x\n",
    "\n",
    "def distance_to_mid_center(lat, lon):\n",
    "    berlin_center = (52.5200, 13.4050)\n",
    "    accommodation = (lat, lon)\n",
    "    return great_circle(berlin_center, accommodation).km\n",
    "\n",
    "\n",
    "def processing(df):\n",
    "    df.drop(columns=columns_to_drop,inplace=True) #specified irrelevant columns \n",
    "    \n",
    "    df.dropna(subset=['Price'], inplace=True)    #drop price missing (9rows)\n",
    "    \n",
    "    df['Listing ID']=df['Listing ID'].apply(drop_virgule)              # Drop the '.0' in IDs and Postal Code\n",
    "    df['Host ID']=df['Host ID'].apply(drop_virgule)\n",
    "    df['Postal Code']=df['Postal Code'].apply(drop_virgule)\n",
    "    \n",
    "    df['Host Since']=pd.to_datetime(df['Host Since'])                  # Convert values to datetime\n",
    "    df['First Review']=pd.to_datetime(df['First Review'])\n",
    "    df['Last Review']=pd.to_datetime(df['Last Review'])\n",
    "    \n",
    "    df['Accomodates'].replace('*', np.nan,inplace=True)                 # Put NaN in missing values where we have *\n",
    "    df['Bathrooms'].replace('*', np.nan,inplace=True)\n",
    "    df['Bedrooms'].replace('*', np.nan,inplace=True)\n",
    "    df['Beds'].replace('*', np.nan,inplace=True)\n",
    "    df['Guests Included'].replace('*', np.nan,inplace=True)\n",
    "    df['Min Nights'].replace('*', np.nan,inplace=True)\n",
    "    df['Postal Code'].replace('*', np.nan,inplace=True)\n",
    "    df['neighbourhood'].replace('*', np.nan,inplace=True)\n",
    "    df['Property Type'].replace('*', np.nan,inplace=True)\n",
    "    df['Host Response Rate'].replace('*', np.nan,inplace=True)\n",
    "\n",
    "    #from 98% to 0.98\n",
    "    df['Host Response Rate'].replace('nan', np.nan,inplace=True)\n",
    "    df['Host Response Rate']=df[~df['Host Response Rate'].isnull()][\"Host Response Rate\"].str.split('%').apply(lambda x:float(x[0])/100)\n",
    "\n",
    "    df['Accomodates'] = df['Accomodates'].astype('float')              # Convert values to float\n",
    "    df['Bathrooms'] = df['Bathrooms'].astype('float')\n",
    "    df['Bedrooms'] = df['Bedrooms'].astype('float')\n",
    "    df['Beds'] = df['Beds'].astype('float')\n",
    "    df['Guests Included'] = df['Guests Included'].astype('float')\n",
    "    df['Min Nights'] = df['Min Nights'].astype('float') \n",
    "    \n",
    "    df.columns = df.columns.str.lower().str.replace(' ','_')           # Rename the columns with '_' instead of ' '\n",
    "\n",
    "    #distance from center of berlin\n",
    "    df['distance_to_midcenter'] = df.apply(lambda x: distance_to_mid_center(x.latitude, x.longitude), axis=1)\n",
    "    return df\n",
    "\n",
    "def processing_2(df):\n",
    "    \n",
    "    numerical_columns = df.select_dtypes(exclude=object).columns   # numeric columns names\n",
    "    categorical_columns = df.select_dtypes(include=object).columns # categorical columns names\n",
    "    \n",
    "    df_cleaned_num = df[numerical_columns]    # dataframe with numeric columns only\n",
    "    df_cleaned_cat = df[categorical_columns]  # dataframe with categorical columns only\n",
    "    \n",
    "    #standardisation for numeric columns\n",
    "    scalerx = StandardScaler() \n",
    "    df_scaled=pd.DataFrame(scalerx.fit_transform(df_cleaned_num), columns = numerical_columns)\n",
    "    \n",
    "    #one encoder for categorical columns\n",
    "    df_encoded=pd.DataFrame() \n",
    "    for cat in categorical_columns:\n",
    "        df_temp = pd.get_dummies(df_cleaned_cat[cat], prefix=cat)\n",
    "        df_encoded=pd.concat([df_temp, df_encoded], axis=1)\n",
    "    \n",
    "    #concatenation of numeric and categorical dataframes\n",
    "    df_scaled.reset_index(drop=True, inplace=True)\n",
    "    df_encoded.reset_index(drop=True, inplace=True)\n",
    "    df_final=pd.concat([df_scaled, df_encoded], axis=1) \n",
    "    \n",
    "    #KNN imputer (n=5 ????)\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df_final = pd.DataFrame(imputer.fit_transform(df_final),columns = df_final.columns)\n",
    "    \n",
    "    return df_final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='train_airbnb_berlin.csv'\n",
    "my_sep,my_encoding=',','utf-8'\n",
    "columns_to_drop=['Listing Name','Host Name','City','Country Code','Country']\n",
    "types={'Listing ID':'str','Host ID':'str','Postal Code':'str'}\n",
    "data=pd.read_csv(path,sep=my_sep,encoding=my_encoding,dtype=types)\n",
    "\n",
    "#processing 1: drop the irrelevant columns / replace '*' values by nan / standardisation of columns name\n",
    "df=processing(data)\n",
    "\n",
    "df.drop(columns=['host_since','last_review','first_review','square_feet',\n",
    "                 'business_travel_ready','host_id','listing_id','host_since',\n",
    "                 'first_review','last_review','neighborhood_group'],inplace=True)\n",
    "\n",
    "# droping outlighers for prices >300\n",
    "df = df[~(df['price'] > 300)]\n",
    "\n",
    "#droping rows where there is more than 3 nan \n",
    "#from dataviz we saw that it was the best option\n",
    "df=df[df.isnull().sum(1)<4]\n",
    "\n",
    "#processing 2: standardisation / one-hot-encoder / KNN imputer\n",
    "df=processing_2(df)\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['price'])\n",
    "y=df['price'].copy()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3568a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=150,\n",
    "    reg_lambda=2,\n",
    "    gamma=1,\n",
    "    max_depth=3\n",
    ")\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb974d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "print('rmse ',math.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('r2   ',metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test) \n",
    "print(y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "print ('mse = {}, rmse = {} \\nmae = {} r2 = {}'.format(mse,math.sqrt(mse), mae, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbf496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None )\n",
    "models,predictions = reg.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5877c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
