{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5706f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "import itertools\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "import xgboost as xgb\n",
    "import math \n",
    "import datetime as dt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from geopy.distance import great_circle\n",
    "from math import sin, cos, sqrt, atan2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac847338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_virgule(x):\n",
    "    try:return x.split('.')[0]\n",
    "    except:return x\n",
    "\n",
    "def distance_to_mid_center(lat, lon):\n",
    "    berlin_center = (52.5200, 13.4050)\n",
    "    accommodation = (lat, lon)\n",
    "    return great_circle(berlin_center, accommodation).km\n",
    "\n",
    "\n",
    "def processing(df):\n",
    "    df.drop(columns=columns_to_drop,inplace=True) #specified irrelevant columns \n",
    "    \n",
    "    df.dropna(subset=['Price'], inplace=True)    #drop price missing (9rows)\n",
    "    \n",
    "    df['Listing ID']=df['Listing ID'].apply(drop_virgule)              # Drop the '.0' in IDs and Postal Code\n",
    "    df['Host ID']=df['Host ID'].apply(drop_virgule)\n",
    "    df['Postal Code']=df['Postal Code'].apply(drop_virgule)\n",
    "    \n",
    "    df['Host Since']=pd.to_datetime(df['Host Since'])                  # Convert values to datetime\n",
    "    df['First Review']=pd.to_datetime(df['First Review'])\n",
    "    df['Last Review']=pd.to_datetime(df['Last Review'])\n",
    "    df['Host Since']=df['Host Since'].map(dt.datetime.toordinal)\n",
    "    df['First Review']=df['First Review'].map(dt.datetime.toordinal)\n",
    "    df['Last Review']=df['Last Review'].map(dt.datetime.toordinal)\n",
    "    \n",
    "    df['Accomodates'].replace('*', np.nan,inplace=True)                 # Put NaN in missing values where we have *\n",
    "    df['Bathrooms'].replace('*', np.nan,inplace=True)\n",
    "    df['Bedrooms'].replace('*', np.nan,inplace=True)\n",
    "    df['Beds'].replace('*', np.nan,inplace=True)\n",
    "    df['Guests Included'].replace('*', np.nan,inplace=True)\n",
    "    df['Min Nights'].replace('*', np.nan,inplace=True)\n",
    "    df['Postal Code'].replace('*', np.nan,inplace=True)\n",
    "    df['neighbourhood'].replace('*', np.nan,inplace=True)\n",
    "    df['Property Type'].replace('*', np.nan,inplace=True)\n",
    "    df['Host Response Rate'].replace('*', np.nan,inplace=True)\n",
    "\n",
    "    #from 98% to 0.98\n",
    "    df['Host Response Rate'].replace('nan', np.nan,inplace=True)\n",
    "    df['Host Response Rate']=df[~df['Host Response Rate'].isnull()][\"Host Response Rate\"].str.split('%').apply(lambda x:float(x[0])/100)\n",
    "\n",
    "    df['Accomodates'] = df['Accomodates'].astype('float')              # Convert values to float\n",
    "    df['Bathrooms'] = df['Bathrooms'].astype('float')\n",
    "    df['Bedrooms'] = df['Bedrooms'].astype('float')\n",
    "    df['Beds'] = df['Beds'].astype('float')\n",
    "    df['Guests Included'] = df['Guests Included'].astype('float')\n",
    "    df['Min Nights'] = df['Min Nights'].astype('float') \n",
    "\n",
    "   \n",
    "    \n",
    "    df.columns = df.columns.str.lower().str.replace(' ','_')           # Rename the columns with '_' instead of ' '\n",
    "\n",
    "    #distance from center of berlin\n",
    "    df['distance_to_midcenter'] = df.apply(lambda x: distance_to_mid_center(x.latitude, x.longitude), axis=1)\n",
    "    for lieu in centres_berlins:                                       # Add distances \n",
    "        df = add_distance_feature(df, lieu)\n",
    "\n",
    "    return df\n",
    "\n",
    "def processing_2(df):\n",
    "    \n",
    "    numerical_columns = df.select_dtypes(exclude=object).columns   # numeric columns names\n",
    "    categorical_columns = df.select_dtypes(include=object).columns # categorical columns names\n",
    "    \n",
    "    df_cleaned_num = df[numerical_columns]    # dataframe with numeric columns only\n",
    "    df_cleaned_cat = df[categorical_columns]  # dataframe with categorical columns only\n",
    "    \n",
    "    #standardisation for numeric columns\n",
    "    #scalerx = MinMaxScaler() \n",
    "    #df_scaled=pd.DataFrame(scalerx.fit_transform(df_cleaned_num), columns = numerical_columns)\n",
    "    \n",
    "    #one hot encoder for categorical columns\n",
    "    df_encoded=pd.DataFrame() \n",
    "    for cat in categorical_columns:\n",
    "        df_temp = pd.get_dummies(df_cleaned_cat[cat], prefix=cat)\n",
    "        df_encoded=pd.concat([df_temp, df_encoded], axis=1)\n",
    "    \n",
    "    #concatenation of numeric and categorical dataframes\n",
    "    df_cleaned_num.reset_index(drop=True, inplace=True)\n",
    "    df_encoded.reset_index(drop=True, inplace=True)\n",
    "    df_final=pd.concat([df_cleaned_num, df_encoded], axis=1) \n",
    "    \n",
    "    #KNN imputer (n=5 ????)\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df_final = pd.DataFrame(imputer.fit_transform(df_final),columns = df_final.columns)\n",
    "    \n",
    "    return df_final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e55d1141",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#liste des lieux emblématiques de Berlin [nom,lat,long]\n",
    "centres_berlins = [[\"charlottenburg\", 52.516602, 13.304105],\n",
    "                   [\"kreuzberg\", 52.498605, 13.391799],\n",
    "                   [\"wedding\", 52.561559, 13.35002],\n",
    "                   [\"mitte\", 52.531677, 13.381777],\n",
    "                   [\"mariendorf\", 52.4333316, 13.3833318],\n",
    "                   [\"tegel\", 52.558833, 13.288437], \n",
    "                   [\"tempelhof\", 52.472160, 13.370287],\n",
    "                   [\"spandau\", 52.534080, 13.181716],\n",
    "                   [\"schöneberg\", 52.497161, 13.346865],\n",
    "                   [\"wilmersdorf\",  52.48333, 13.31667],\n",
    "                   [\"biesdorf\", 52.508429, 13.563317],\n",
    "                   [\"moabit\", 52.530832, 13.345876],\n",
    "                   [\"britz\", 52.45, 13.433333],\n",
    "                   [\"neukölln\", 52.440771, 13.444507],\n",
    "                   [\"dahlem\", 52.466562, 13.300082], \n",
    "                   [\"tiergarten\", 52.51449, 13.350091],\n",
    "                   [\"hellersdorf\", 52.536107, 13.604973],\n",
    "                   [\"prenzlauer_berg\", 52.550113, 13.423125], \n",
    "                   [\"friedrichshain\", 52.515816, 13.454293],\n",
    "                   [\"reinickendorf\", 52.566667, 13.333333],\n",
    "                   [\"friedrichsfelde\", 52.503664652, 13.507664636],\n",
    "                   [\"friedenau\", 52.47133, 13.32813],\n",
    "                   [\"gesundbrunnen\", 52.548611, 13.390278],\n",
    "                   [\"charlottenbourg_nord\", 52.53048, 13.29371],\n",
    "                   [\"hansaviertel\", 52.5166646, 13.33666532],\n",
    "                   [\"haselhorst\", 52.54409, 13.23743],\n",
    "                   [\"gropiusstadt\", 52.425, 13.46667],\n",
    "                   [\"westend\", 52.5166646, 13.2833322],\n",
    "                   [\"wittenau\", 52.592455, 13.329694],\n",
    "                   [\"zehlendorf\", 52.435077, 13.260425],\n",
    "                   [\"lichtenberg\", 52.534306, 13.502326],\n",
    "                   [\"pankow\", 52.592879, 13.431700],\n",
    "                   [\"steglitz\", 52.453096, 13.331171],\n",
    "                   [\"siemenstadt\", 52.537664516, 13.257832302],\n",
    "                   [\"rudow\", 52.402310, 13.509220],\n",
    "                   [\"kaulsdorf\", 52.506512, 13.593946]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cfeac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_feature(df, lieu):\n",
    "    name_column = \"distance_\" + str(lieu[0])\n",
    "    df[name_column] = df.apply(lambda x : distance(x['latitude'], x['longitude'], lieu[1], lieu[2]), axis = 1)\n",
    "    return df\n",
    "def distance(lat1,lon1,lat2,lon2):\n",
    "    R = 6373.0\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = (sin(dlat/2))**2 + cos(lat1) * cos(lat2) * (sin(dlon/2))**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "661f8384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Square Feet</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Overall Rating</th>\n",
       "      <th>Accuracy Rating</th>\n",
       "      <th>Cleanliness Rating</th>\n",
       "      <th>Checkin Rating</th>\n",
       "      <th>Communication Rating</th>\n",
       "      <th>Location Rating</th>\n",
       "      <th>Value Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15692.000000</td>\n",
       "      <td>15692.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>15692.000000</td>\n",
       "      <td>12730.000000</td>\n",
       "      <td>12721.000000</td>\n",
       "      <td>12722.000000</td>\n",
       "      <td>12719.000000</td>\n",
       "      <td>12722.000000</td>\n",
       "      <td>12721.000000</td>\n",
       "      <td>12720.000000</td>\n",
       "      <td>15683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.509893</td>\n",
       "      <td>13.407334</td>\n",
       "      <td>445.900990</td>\n",
       "      <td>19.452014</td>\n",
       "      <td>94.717282</td>\n",
       "      <td>9.717475</td>\n",
       "      <td>9.328407</td>\n",
       "      <td>9.769164</td>\n",
       "      <td>9.779201</td>\n",
       "      <td>9.556874</td>\n",
       "      <td>9.458097</td>\n",
       "      <td>60.342983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031286</td>\n",
       "      <td>0.058646</td>\n",
       "      <td>414.817342</td>\n",
       "      <td>39.483853</td>\n",
       "      <td>7.069787</td>\n",
       "      <td>0.671793</td>\n",
       "      <td>1.023807</td>\n",
       "      <td>0.620347</td>\n",
       "      <td>0.619545</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.788891</td>\n",
       "      <td>48.829687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>52.369270</td>\n",
       "      <td>13.121400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>52.488920</td>\n",
       "      <td>13.376025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.509100</td>\n",
       "      <td>13.417250</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.532713</td>\n",
       "      <td>13.439750</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.639670</td>\n",
       "      <td>13.709020</td>\n",
       "      <td>1912.000000</td>\n",
       "      <td>424.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Latitude     Longitude  Square Feet       Reviews  Overall Rating  \\\n",
       "count  15692.000000  15692.000000   303.000000  15692.000000    12730.000000   \n",
       "mean      52.509893     13.407334   445.900990     19.452014       94.717282   \n",
       "std        0.031286      0.058646   414.817342     39.483853        7.069787   \n",
       "min       52.369270     13.121400     0.000000      0.000000       20.000000   \n",
       "25%       52.488920     13.376025     0.000000      1.000000       93.000000   \n",
       "50%       52.509100     13.417250   440.000000      5.000000       97.000000   \n",
       "75%       52.532713     13.439750   700.000000     17.000000      100.000000   \n",
       "max       52.639670     13.709020  1912.000000    424.000000      100.000000   \n",
       "\n",
       "       Accuracy Rating  Cleanliness Rating  Checkin Rating  \\\n",
       "count     12721.000000        12722.000000    12719.000000   \n",
       "mean          9.717475            9.328407        9.769164   \n",
       "std           0.671793            1.023807        0.620347   \n",
       "min           2.000000            2.000000        2.000000   \n",
       "25%          10.000000            9.000000       10.000000   \n",
       "50%          10.000000           10.000000       10.000000   \n",
       "75%          10.000000           10.000000       10.000000   \n",
       "max          10.000000           10.000000       10.000000   \n",
       "\n",
       "       Communication Rating  Location Rating  Value Rating         Price  \n",
       "count          12722.000000     12721.000000  12720.000000  15683.000000  \n",
       "mean               9.779201         9.556874      9.458097     60.342983  \n",
       "std                0.619545         0.731109      0.788891     48.829687  \n",
       "min                2.000000         2.000000      2.000000      8.000000  \n",
       "25%               10.000000         9.000000      9.000000     32.000000  \n",
       "50%               10.000000        10.000000     10.000000     49.000000  \n",
       "75%               10.000000        10.000000     10.000000     70.000000  \n",
       "max               10.000000        10.000000     10.000000    900.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path='train_airbnb_berlin.csv'\n",
    "path='/Users/Pierr/OneDrive/Documents/CentraleSupelec/MLAirBnb/train_airbnb_berlin.csv'\n",
    "my_sep,my_encoding=',','utf-8'\n",
    "columns_to_drop=['Listing Name','Host Name','City','Country Code','Country']\n",
    "types={'Listing ID':'str','Host ID':'str','Postal Code':'str'}\n",
    "data=pd.read_csv(path,sep=my_sep,encoding=my_encoding,dtype=types)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91a4bebe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#processing 1: drop the irrelevant columns / replace '*' values by nan / standardisation of columns name\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[39m=\u001b[39mprocessing(data)\n\u001b[0;32m      4\u001b[0m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39msquare_feet\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mbusiness_travel_ready\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mhost_id\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlisting_id\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mneighborhood_group\u001b[39m\u001b[39m'\u001b[39m],inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# droping outlighers for prices >300\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [42], line 23\u001b[0m, in \u001b[0;36mprocessing\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     21\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mFirst Review\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m'\u001b[39m\u001b[39mFirst Review\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mLast Review\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m'\u001b[39m\u001b[39mLast Review\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mHost Since\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mHost Since\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap(dt\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mtoordinal)\n\u001b[0;32m     24\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mFirst Review\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mFirst Review\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap(dt\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mtoordinal)\n\u001b[0;32m     25\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mLast Review\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mLast Review\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmap(dt\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mtoordinal)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#processing 1: drop the irrelevant columns / replace '*' values by nan / standardisation of columns name\n",
    "df=processing(data)\n",
    "\n",
    "df.drop(columns=['square_feet','business_travel_ready','host_id','listing_id','neighborhood_group'],inplace=True)\n",
    "\n",
    "# droping outlighers for prices >300\n",
    "df = df[~(df['price'] > 300)]\n",
    "\n",
    "#droping rows where there is more than 3 nan \n",
    "#from dataviz we saw that it was the best option\n",
    "df=df[df.isnull().sum(1)<4]\n",
    "\n",
    "#processing 2: standardisation / one-hot-encoder / KNN imputer\n",
    "df=processing_2(df)\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a29db6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def MSE(y_true,y_pred):\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    print ('MSE: %2.3f' % mse)\n",
    "    return mse\n",
    "\n",
    "def R2(y_true,y_pred):    \n",
    "     r2 = metrics.r2_score(y_true, y_pred)\n",
    "     print ('R2: %2.3f' % r2)\n",
    "     return r2\n",
    "\n",
    "def two_score(y_true,y_pred):    \n",
    "    #MSE(y_true,y_pred) #set score here and not below if using MSE in GridCV\n",
    "    score = R2(y_true,y_pred)\n",
    "    return score\n",
    "\n",
    "def two_scorer():\n",
    "    return metrics.make_scorer(two_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91c2f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['price'])\n",
    "y=df['price'].copy()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c2f4955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=500, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "             reg_alpha=0.05, reg_lambda=0.05, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=500, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "             reg_alpha=0.05, reg_lambda=0.05, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.3,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=500, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "             reg_alpha=0.05, reg_lambda=0.05, ...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    reg_alpha=0.05,\n",
    "    reg_lambda = 0.05,\n",
    "    colsample_bytree = 0.3,\n",
    "    max_depth=3\n",
    ")\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df3fda33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse  29.605606284691564\n",
      "r2    0.4729883528191492\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "print('rmse ',math.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('r2   ',metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = { 'max_depth': [3,6],\n",
    "           'learning_rate': [0.0001,0.01, 0.05, 0.1, 0.15],\n",
    "           'n_estimators': [100, 250, 500, 600],\n",
    "           'colsample_bytree': [0.3]}\n",
    "xgbr = xgb.XGBRegressor()\n",
    "clf = GridSearchCV(estimator=xgbr, \n",
    "                   param_grid=params,\n",
    "                   scoring=two_scorer(), \n",
    "                   verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "best_params = clf.best_params_\n",
    "model = clf.best_estimator_\n",
    "score = clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4f72e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 822.2612876985814, rmse = 28.675098739125232 \n",
      "mae = 19.353864205186383 r2 = 0.5055958143681585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test) \n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "print ('mse = {}, rmse = {} \\nmae = {} r2 = {}'.format(mse,math.sqrt(mse), mae, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7800c028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m# Instantiate the grid search model\u001b[39;00m\n\u001b[0;32m     15\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator \u001b[39m=\u001b[39m rf, param_grid \u001b[39m=\u001b[39m param_grid, \n\u001b[0;32m     16\u001b[0m                           cv \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m, n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, verbose \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     19\u001b[0m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\Pierr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Pierr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Pierr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Pierr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\Pierr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\Pierr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pierr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Pierr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10,20,30,40],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1d80ad67319cdf01eb41b135f33e23f51f5b7f0fa6cd51dd5f6d9ed8aa4c9a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
